{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# title: Graph Convolutional Networks: Model Relations In Data\n",
    "\n",
    "##### revised based on the reference: https://www.learnopencv.com/graph-convolutional-networks-model-relations-in-data/, and\n",
    "#####  https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0\n",
    "##### ☆☆☆ https://github.com/spmallick/learnopencv\n",
    "\n",
    "## 1. the problem of Multi Label Image Classification (MLIC) for Image Tagging.\n",
    "1. Categories.\n",
    "  + Binary Classification\n",
    "  + Multi-class classification\n",
    "  + Multi-output classification\n",
    "  + <span style=\"color:#B40431;background-color:#FBEFF2\"> Multi-label classification </span>\n",
    "  \n",
    "### 1.1 Labels are Correlated\n",
    "#### BW: <span style=\"color:#B40431;background-color:#FBEFF2\"> Labels/Parts/Components are Correlated </span>\n",
    "   Notice some of the tags are not independent. For example, if there is a sky label for an image, the probability of seeing the cloud or sunset labels for the same picture are high. The same holds true for the labels ocean, lake, and water labels.\n",
    "\n",
    "   So it’s logical to assume that labels aren’t independent since in real life such objects or aspects are interconnected.\n",
    "\n",
    "   This intuition is a core idea behind the most recent papers for MLIC. Researchers are trying to use prior knowledge about connections between labels to get better results.\n",
    "\n",
    "   In the paper “[Multi-Label Image Recognition with Graph Convolutional Networks, 2019](https://arxiv.org/pdf/1904.03582.pdf)” the authors use **Graph Convolutional Network** (GCN) to encode and process relations between labels, and as a result, they get a 1–5% accuracy boost.\n",
    "    \n",
    "   The paper “[Cross-Modality Attention with Semantic Graph Embedding for Multi-Label Classification, 2020](https://arxiv.org/pdf/1912.07872.pdf)” proposes the further development of this idea. The authors added special attention to the approach from the former paper and obtained an additional 1–5% accuracy boost.\n",
    "\n",
    "### 1.2 (Directional) Graph \n",
    "### BW: If it is directional graph, then row stands for the start node and column stands for the end node.\n",
    "1. Before we move to the explanation of what GCNs are and how they’re applied to the task at hand, we should understand what are graphs and how are they related to our problem.\n",
    "\n",
    "2. In CS, a **graph** is a structure that encodes relationships between objects.\n",
    "\n",
    "3. In a graph, objects are represented using “nodes” while an “edge” between the nodes represents the relationship between the pair of the nodes.\n",
    "    \n",
    "    The edges may have their own weights to represent the strength of relationship between nodes. In such cases, the graph is **a weighted graph**.\n",
    "\n",
    "4. Now, let’s look at some synthetical example that illustrates our image tagging task. Imagine we have a dataset with some vacation photos and 4 possible labels: ‘Sea’, ‘Sky’, ‘Sunset’, ‘Cloud’.\n",
    "\n",
    "    We also have 8 data samples with the following labels assigned to them:\n",
    "        1: ‘Sea’, ‘Sky’, ‘Sunset\n",
    "        2: ‘Sky’, ‘Sunset’\n",
    "        3: ‘Sky’, ‘Cloud’\n",
    "        4: ‘Sea’, ‘Sunset’\n",
    "        5: ‘Sunset’, ‘Sea’\n",
    "        6: ‘Sea’, ‘Sky’\n",
    "        7: ‘Sky’, ‘Sunset’\n",
    "        8: ‘Sunset’\n",
    "\n",
    "    We can represent the labels as the graph nodes, but what are the connections between them? We propose to add connections between each pair of labels with weights reflecting the probability of some label’s appearance given that another label is already here.\n",
    "    \n",
    "    Let’s elaborate a bit on that. The probability of each label in our dataset would be just the ratio of samples with this label divided by the total number of data samples. We’ve already noticed that some labels often come in pairs. This particular feature can be represented using the conditional probability, that’s $P(L_j|L_i)$, which denotes the probability of occurrence of label $L_j$ when label $L_i$ appears.\n",
    "\n",
    "### 1.3 Adjacency matrix\n",
    "1. Now let’s take a moment to talk about how we can represent the graph structure to make use of it in our DL pipeline.\n",
    "    There are dozens of ways to represent graphs, but here we want to focus on a popular method that also fits our requirements – **adjacency matrix**.\n",
    "\n",
    "2. For model training, we can compute this matrix based on the training dataset. First, we count the occurrences of label pairs in the training set and get the matrix $A\\in R^{CxC}$ . Here, $C$ is the number of labels, $L_i$ is a specific label, and $A_{ij}$ denotes the number of samples with both labels $L_i$ and $L_j$.\n",
    "    ![adjacency_matrix_01](./img/adjacency_matrix_01.png)\n",
    "   \n",
    "   We can calculate the number of occurrences for each label Li in the training dataset:\n",
    "      ![adjacency_matrix_02](./img/adjacency_matrix_02.png)\n",
    "      \n",
    "   Then, by dividing this label co-occurrence matrix row by row (that’s $P_i = \\frac{A_i}{N_i}$), we can get the conditional probabilities for each pair of labels.\n",
    "      ![adjacency_matrix_03](./img/adjacency_matrix_03.png)\n",
    "   Lastly, we add self-loops, because the probability of some label being on an image if it’s already here is 1:\n",
    "      ![adjacency_matrix_04](./img/adjacency_matrix_04.png)\n",
    "    vip: $P = P + Identity(length(P))$\n",
    "   \n",
    "   And now we have our weighted adjacency matrix which represents a directed weighted graph with 4 nodes and edges weighted according to the probability of each label pair co-occurrence.\n",
    "    ![adjacency_matrix_05](./img/adjacency_matrix_05.png)\n",
    "   Note that probabilities $P(L_i|L_j)$ and $P(L_j|L_i)$ are not equal and that’s normal. For instance if there is a Cloud, the probability of having Sky is 1.0. But if there is a sky, the probability of Cloud is 0.2 – the sky may have no clouds.\n",
    "\n",
    "### 1.4 Graph Convolution vs Convolution\n",
    "We all know about a standard Convolution layer. It works as a filter and extracts features from numerical data (such as images, signals, etc.). The graph convolution layer has the same logic. It works as a filter and extracts the features from graphs. To draw more parallels between them, it’s better to think about *the image as a graph with adjacent pixels connected by edges*.\n",
    "   ![adjacency_matrix_06](./img/adjacency_matrix_06.png)\n",
    "\n",
    "### 1.5 Graph Convolution in general\n",
    "1. In the Convolution layer, we use the size of the convolution kernel to indicate the size of the neighborhood (how many pixels will contribute to the resulting value). Similarly, the Graph Convolution layer uses neighbors of a particular graph node to define a convolutional operation in it. Two nodes are neighbors if they have a common edge. In Graph Convolutions a learnable weight is multiplied by features of all the neighbors of a particular node (including the node itself) and some activation function is applied on top of the result. Formally, the result of Graph Convolution applied at node $v_{i}$ with a corresponding feature vector $h_{v_{i}}$ would be:\n",
    "  \\begin{equation}\n",
    "    \\hat{h}_{v_{i}}=f\\left(\\sum_{j \\in N} \\frac{1}{c_{i j}} h_{v_{j}} W\\right)\n",
    "   \\end{equation}\n",
    "  Here $N$ is an index set of neighborhood nodes of the node $v_i$ (it also includes i), $W$ is a learnable weight that is the same for all nodes in the neighborhood, and $f$ is some non-linear activation function.\n",
    "\n",
    "2. Let’s now explain what <span style=\"color:#B40431;background-color:#FBEFF2\"> $c_{ij}$ </span> is and how to implement this operation. It’s a constant parameter for the edge $(v_i, v_j)$ from the symmetrical normalization matrix. We compute this matrix by multiplying inversed degree matrix $D$ and binary adjacency matrix $A$ (we will describe how to get **binary adjacency matrix** from the weighted one further), so <span style=\"color:#B40431;background-color:#FBEFF2\"> symmetric normalization matrix </span> is computed once for the input graph as follows:\n",
    "  \\begin{equation}\n",
    "    D^{-1/2} A D^{-1/2}\n",
    "  \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5+ Graph Convolution in general (an alternative)\n",
    "###### ref: https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780\n",
    "\n",
    "3. An alternative discription of the content above: A hidden layer in the GCN can thus be written as $H_i=f(H_{i-1}, A)$ where $H_0=x$ and $f$ is a propagation. Each layer $H_i$ corresponds to an $N\\times F_i$ feature matrix where each row is a feature representation of a node.\n",
    "   \n",
    "   One of the simplest possible propagation rule is:\n",
    "    \\begin{equation}\n",
    "    f(H_i, A) = \\sigma(A H_i W_i)\n",
    "    \\end{equation}\n",
    "   where $W_i$ is the weight matrix for layer $i$ and $\\sigma$ is a non-linear activation function such as the ReLU function. The weight matrix has dimensions $F_i \\times F_{i+1}$; in other words the size of the second dimension of the weight matrix determines the number of features at the next layer. If you are familiar with convolutional neural networks, this operation is similar to a filtering operation since these weights are shared across nodes in the graph.\n",
    "   \n",
    "   ☆When we apply the propagation rule, what happened? The representation of each node (each row) is now a sum of its **neighbors** features (**not all the nodes,just neighbors**)! In other words, the graph convolutional layer represents each node as an aggregate of its **neighborhood (should includes itself)**. Note that in this case a node n is a **neighbor** of node v if there exists an edge from v to n.\n",
    "   \n",
    "   1/2. Should add the node itself to the neighborhood.\n",
    "   2/2. Should perform normalization on the adjacency matrix before use by:\n",
    "    ```python\n",
    "        D = np.array(np.sum(A, axis=0))[0] \n",
    "        D = np.matrix(np.diag(D)\n",
    "        A = D**-1 * A\n",
    "    ```\n",
    "    Observe that the weights (the values) in each row of the adjacency matrix have been divided by the degree of the node corresponding to the row. Note that here D_hat is the degree matrix of A_hat = A + I, $X_{NextLayer} = ReLU(\\hat{D}**-1 * \\hat{A} * X * W)$. And if we want to reduce the dimensionality of the output feature representations we can reduce the size of the weight matrix W.\n",
    "    \n",
    "    The Zachary’s Karate Club data (small and efficient). It is a commonly used social network where nodes represent members of a karate club and the edges their mutual relations. While Zachary was studying the karate club, a conflict arose between the administrator and the instructor which resulted in the club splitting in two. The figure below shows the graph representation of the network and nodes are labeled according to which part of the club. The administrator and instructor are marked with ‘A’ and ‘I’, respectively.\n",
    "    ![zachary_karate_club_01](./img/zachary_karate_club_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zachary's Karate Club\n",
      "A=[[0. 1. 1. ... 1. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 1. ... 1. 0. 1.]\n",
      " [0. 0. 0. ... 1. 1. 0.]]\n",
      "D_hat=[[17.  0.  0. ...  0.  0.  0.]\n",
      " [ 0. 10.  0. ...  0.  0.  0.]\n",
      " [ 0.  0. 11. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  7.  0.  0.]\n",
      " [ 0.  0.  0. ...  0. 13.  0.]\n",
      " [ 0.  0.  0. ...  0.  0. 18.]]\n",
      "{0: array([0.24368022, 0.19348343]), 1: array([0.21933729, 0.1847019 ]), 2: array([0.21541014, 0.22453917]), 3: array([0.2265379 , 0.15881686]), 4: array([0.08529807, 0.10486235]), 5: array([0.29738095, 0.26548904]), 6: array([0.21591773, 0.19452078]), 7: array([0.10698082, 0.10698642]), 8: array([0.        , 0.07070385]), 9: array([0.        , 0.27950499]), 10: array([0.36494712, 0.25178481]), 11: array([0.        , 0.00507978]), 12: array([0.36864978, 0.15505683]), 13: array([0.02931134, 0.09845684]), 14: array([0.        , 0.07002836]), 15: array([0.08517427, 0.16104759]), 16: array([0.36316698, 0.32541855]), 17: array([0.00161597, 0.01691134]), 18: array([0.19386506, 0.23048766]), 19: array([0.        , 0.01490218]), 20: array([0.13662733, 0.20723527]), 21: array([0.21248324, 0.13888691]), 22: array([0.24162621, 0.0965418 ]), 23: array([0.21421027, 0.0785223 ]), 24: array([0.03050565, 0.08533071]), 25: array([0.15243572, 0.12703983]), 26: array([0.2619011 , 0.10148254]), 27: array([0.06093152, 0.0981299 ]), 28: array([0.02383941, 0.1577901 ]), 29: array([0.28949336, 0.10532399]), 30: array([0.        , 0.05949815]), 31: array([0.04190199, 0.09382058]), 32: array([0.32507023, 0.28712523]), 33: array([0.40090763, 0.31647571])}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAH6CAYAAAC6QhDmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzde1zW9f3/8cdL8EDzQJYUh1Irh4gmKNP6upnWCGfOAzZruW+aWq3Vvv10obbWzPYtSdfSlt/Wcbm11To4dOawlFp925xaYJpGumLJZaZ9kzyEhvj+/XFdEOCFisL1+SDP++123eB6f04vQOXp+/3+vD/mnENERERE/KuV1wWIiIiIyNEpsImIiIj4nAKbiIiIiM8psImIiIj4nAKbiIiIiM8psImIiIj4nAKbiDSImXUzM2dmT3ldi/ibmd0V+rMy5CTPMyR0nrsapzKR5keBTcTHzKwk9IvqeF5PeV1vc1QjDLxWz/YrzGy/mZWb2agIl1cvL4KzmbUysyvN7EUz22ZmB0Lfm81m9qiZDYpULSItTbTXBYjIUc0HYo+y/TRgGhAFbIxIRS2ImU0EHgP2AiOdc//rbUXeMbOzgReAQQS/H68A/wIM6AF8H7jezP7LOfdrzwoVOUUpsIn4mHNufn3bzMyA5wiGtReB+yNVV0tgZjOBOUApMMw5967HJXnGzE4D8oG+wLPAj5xzu+vs0xG4DegY+QpFTn0aEhVpvu4GrgQKgWtdjefMmVmCmf3czN40sx1m9qWZbTezP5pZSn0nNLMBZvYnMwuY2UEz+9jMXjazcfXs383MnjWzT0PDY+vMbESY/TqZWY6ZFZhZaaieXWa21MwuqufczsxeM7OzzezxUE2VZjYxdE1nZoPrOfbK0PYG9/RY0AKCYW0T8B91w5qZtTGzW8xsuZn9O/S9+szMVprZd+o5b0no1dHMfhX6vKJqXlZDfmahYz4MvZ1QZ2h8Yp19s0J1fhqq819mNs/MjtZzW9dUgmHtTWB83bAG4Jzb45z7OfDLo53oWEO5oZ95vc9MNLOLQ9/nz81sr5mtMLOMBnwtIs2SethEmiEzuxr4GbCD4FDdF3V2GQzMBF4l2Pu2j+Cw1ZXASDMb5JxbX+ec1wMPA5XAUmALEAdkAD8i2JtXU1dgDfAB8HugM3AVsMTMvu2ce7XGvinAPcDrwEvAbuBcYCTwHTP7rnMuP8yX2hlYHap/MXAY+AT4n9C1bgyds64bQh8fDbOtXmbWBlgEXA38Hfiuc+6zeupaENrnFWAXEA98F1huZtc75x4Pc1wboCB0/MvAHr4KXg35mb1GcKj8VmA9kFfjGkU1vp6fA7OBz4BlwE7gQoI9YcPN7GLn3J7j+NZUfT9/4Zw7fLQdnXMHj+N8J2ogcDuwElgIXABkA4PN7HLn3BtNeG0Rbznn9NJLr2b0AgYA5aHXwHr2iQM6hGnvSzAI/LVOey+gguAv9tQwxyXV+Lwb4EKvWXX2ywq1L6/T3gk4M9x5ge3A5jDbqq7xOyA6zPaNwIG65wW6Ewx2bx7n93NI6DrrCIYvRzCwxhzlmLY1vyd1vs6Noe9jTJ1tJaFzrwS+1gg/s6qfw1P11Dg0tP3vQGydbRND2x44ju/POaF9K4B2Dfyzelfo2CENqPu14K+msD8jB9xSZ9uoUPsWoNWJ/r3SSy+/vzQkKtKMmFkiwd6UdsAU59w/w+3nnNvpnNsbpn09wR6eoWbWusammwj2uP/ChZmr5ZwrDXOZfwP/XWe/FcBHBENlzfbPnXOf1nPeF4CeZnZumGt8CdzmnDsUZtvDBIPThDrtNxCcCP9ImGOOpj/wbaAYyHbOlde3o3PuYLjviXPuc+BJ4HTgG/Uc/hPn3P4wxzb0Z3Ys/xX6eL1zrqzOOZ8i2BM3/jjOEx/6+H/OuQMNuH5T2Eqwd7Wac24J8DeCvW3f8qIokUjQkKhIMxGa+L2U4C/QOc65Pxxj/yuAHxIc0jyTI/++nwl8HPq8ah7ZXxtQUpFzrjJM+zbg4jD1DCI4hHcxwd6kNnV2SSQY9moqcc7trOf6vwNyCQa0+0PXaE2w92g3Rw7hHksxwQCYDPzazH7knDvaXKpUIIfgUGY8wRBdU2KYww4A7xzlnA35mR3LxQR7xb5nZt8Ls70N0MXMznDO/d9RzmOhj/V+LyLoDRd+SPY14BIgnWB4EznlKLCJNAOhO0IXAf2AJcAdx9j/vwjOsdpNcJjvI+ALgr90RxMcZmtb45CqCeiBBpRVVk/7Ierc0GRmYwj2pB3gq+Ug9hMcuhxC8JdtW460o76LO+f2mtnTwA/NbKgLzpkbBZwNzD+B3qAdwH8CqwiGpnZmNjlcQAjdKFFA8N/QVQSD9J7Q15MWqiPc17OzvhB4Aj+zYzkjVN+sY+zXHjhaYNse+nimmbXzuJftk3raq/6cdIpUISKRpsAm0jzMJjj5/B3gB8fo+YkO7b8D6Oec+7jO9iN6v/gqfCUC7zVKxbX9guDwZoZzbnOdeh4hGNjCOVavzsMEw9WNBCfrn9DNBtUXc25b6M7TVQR76tqZ2X+GGZL9GRADDHXOvVZzg5ndTjCwhb1EuMYT/Jkdy+cE53R1PoFjq4W+Jx8RvElkMMGbJU5GVQCu7/fP0e5ePaue9rNDHz8/oYpEmgHNYRPxudAdoXcSvMNvpHNu3zEOOZPgL72/h/nF355gL11dq0Mfwy5J0QguADaFCWutgG+e6Emdc+8QXGpijJkNJDgH7fW612ngOXcQDJBFBO8WfT5092hNFwCf1Q1rIfWFz6M5kZ9Z1XB0VD3nXA2cHhq6PVlVAfhnoZ9ZvczsWL2AVUuCnBPm2I7A149y7Dfruf6Q0MfCY1xbpNlSYBPxMTP7BvBbgr1T2c65fx/HYTsJDqX1D/2yrzpXa4JDbmeGOeZhgkOZd5pZrzB1JJ1A+TWVAD3MLKHGOY3gcN0R12ughwnOx3qR4Hyr35zk+QjdIDEU+CfB4cg8M6s5R60E6GxmF9Y8zswmE7xTtqFO5Ge2m2CPXbibNQAeCH18rOb3vca5v2b1rIFXz7nWE5zU/7twa7iZWfvQMiK3He1EoRsr3gMG1fyzZmZRwK8I9lzWpwfBJWZqXncUwZC8FdCyHnLK0pCoiE+ZWQeC89XaAWuBTDPLPMohJc65p5xzh83sQYJrem0wsyUEA81Qgut/vRr6vJpzbpOZ/Yhg2CkMHbOF4DyoDIKPIqp1TAM9UOPcLxKcDD+IYFj7C8H1y07U86HzJwKfElyv7aQ558pC3++XCPY8vmRmI0N3eM4nGMz+18yeIzgUl0Gwt/AFgsPXDbnWifzM9pnZP4FvmdkfgPcJraHnnHvHObfKvnpawxYzW05wzbf2BNfQuwT4X2DYcdT3hZkNC31t44HvmtkrBENSK4I9jpcRfMrBLcfxJc8DngDeNLPnCc5tHAq0JhgM+9ZzXD5wvwUXJ17PV+uwHQDCzjcUOWV4va6IXnrpFf5F7fXOjuf1Wo1jowk+Y3QTwfXadhBc3LYr8FRo/25hrnkxwZ6qnQR79bYT/CV5ZZi6nqqn7teos45WqH0iwWHG/QSD1Z+BPoRZqyu0f62v6RjfqwdC+887ge/zkKNdi+DzWqvWZ/tfoGOofQTBYce9BOcAvkxwjtfE0L4T65ynhGCorq+OBv/MCAaWvxC8aeBwPdf9JsE7ZreHfqa7Qj+HXxGcU9iQ71Ur4HsEQ3EpwaD0BcEes8cJPhWi5v5hf7ahbZOBd4GDoa/1EYL/QTjiz0+Nn9FdoT+jKwne5LE39H3/htd/X/XSq6lf5pwf7tQWETlxZvYawbCU7Jzb4nE5IiKNTnPYRKRZM7MBBIf3ViisicipSnPYRKRZMrObCM5bu47gcOCx1hsTEWm2NCQqIs2SmZUQfBbpB8Bdzrk/eluRiEjTUWATERER8TnNYRMRERHxuVN6DtuZZ57punXr5nUZIiIiIsf01ltvfeqc6xJu2ykd2Lp168a6deu8LkNERETkmMys3qfZaEhURERExOcU2ERERER8ToFNRERExOcU2ERERER8ToFNRERExOcU2ERERER8ToFNRERExOcU2ERERER8ToFNRERExOcU2ERERER8ToFNRERExOcU2ERERER8ToFNRERExOcU2ERERER8ToFNRERExOcU2ERERER8ToFNRERExOcU2ERERER8ToFNREREGt2kSZOIi4ujd+/etdp//etfk5ycTGpqKtOnT/eouuZHgU1EREQa3cSJE8nPz6/V9uqrr7JkyRLeeecd3n33XW677TaPqmt+FNhERESk0Q0ePJjOnTvXanv44YeZOXMmbdu2BSAuLs6L0polBTYRERGJiPfff5833niDgQMHcskll7B27VqvS2o2or0uQERERFqGQ4cOsXv3blavXs3atWsZN24cH3zwAWbmdWm+p8AmIiIijSKvMMC8FcVsLysnITaGCX1Oq7U9KSmJ7OxszIwBAwbQqlUrPv30U7p06eJRxc2HhkRFRETkpOUVBrh98QYCZeU4IFBWzn35xew5cKh6n9GjR1NQUAAEh0e//PJLzjzzTI8qbl7UwyYiIiInbd6KYsorKqvf71o6l4MfbeBw+R6SkpKYPXs2kyZNYtKkSfTu3Zs2bdqwaNEiDYceJwU2EREROWnby8prve8yMrjGmgEf5l5R3f70009HsqxThoZERURE5KQlxMY0qF0aRoFNRERETlpOVjIxraNqtcW0jiInK9mjik4tCmwiIiJy0kanJzInuw+JsTEYkBgbw5zsPoxOT/S6tAY5cOAAAwYMoG/fvqSmpjJr1iwAJk+eTN++fbnwwgu58sor2bdvX0TrMudcRC8YSRkZGW7dunVelyEiIiLNhHOO/fv30759eyoqKvjmN7/JggUL6NWrFx07dgRg2rRpxMXFMXPmzEa9tpm95ZzLCLdNPWwiIiIiIWZG+/btAaioqKCiogIzqw5rzjnKy8sjfnerApuIiIhIDZWVlaSlpREXF0dmZiYDBw4E4LrrruPss8/mvffe48c//nFEa1JgExERkRYtrzDAoNwCus98iUG5BfzlnR0UFRVRWlrKmjVr2LhxIwC//e1v2b59OykpKfzpT3+KaI0KbCIiItJihXtCw+2LN5BXGCA2NpYhQ4aQn59fvX9UVBRXXXUVL774YkTrVGATERGRFqvuExoqv/ic/Xs/D7aXl7Ny5UqSk5PZunUrEJzD9pe//IWePXtGtE496UBERERarLpPaKjc9xmfvvQAO9xhvvH01xg3bhxXXHEF3/rWt9izZw/OOfr27cvDDz8c0ToV2ERERKTFSoiNIVAjtLWJ607CdQ+SGBvDmzMvrW5/8803vSivmoZERUREpMVqLk9oUA+biIiItFhVT2KYt6KY7WXlJMTGkJOV7LsnNCiwiYiISIs2Oj3RdwGtLg2JioiIiPicApuIiIiIzymwiYiIiPicApuIiIiIzymwiYiIiPicApuIiIiIzymwiYiIiPicApuIiIiIzymwiYiIiPicApuIiIiIzymwiYiIiPhcxAObmQ0zs2Iz22pmM8Ns/6GZbTCzIjP7XzPrVWPb7aHjis0sK7KVi4iIiHgjooHNzKKAhcB3gF7A92sGspA/Ouf6OOfSgLnAr0LH9gKuBlKBYcD/hM4nIiIickqLdA/bAGCrc+4D59yXwLPAqJo7OOf21Hj7NcCFPh8FPOucO+ic+xDYGjqfiIiIyCktOsLXSwS21XhfCgysu5OZ3QxMA9oAl9Y4dnWdYxObpkwRERER/4h0D5uFaXNHNDi30Dl3PjAD+FlDjjWzG8xsnZmt27Vr10kVKyIiIuIHkQ5spcA5Nd4nAduPsv+zwOiGHOuce9Q5l+Gcy+jSpctJlisiIiLivUgHtrVADzPrbmZtCN5EsLTmDmbWo8bbK4Atoc+XAlebWVsz6w70ANZEoGYRERERT0V0Dptz7pCZ3QKsAKKAJ51z75rZ3cA659xS4BYz+zZQAewGJoSOfdfMngM2AYeAm51zlZGsX0RERMQL5twR08BOGRkZGW7dunVelyEiIiJyTGb2lnMuI9w2PelARERExOcU2ERERER8ToFNRETEpw4cOMCAAQPo27cvqampzJo1C4Dx48eTnJxM7969mTRpEhUVFR5XKk1NgU1ERMSn2rZtS0FBAevXr6eoqIj8/HxWr17N+PHjee+999iwYQPl5eU8/vjjXpcqTSzSTzoQERGR42RmtG/fHoCKigoqKiowM4YPH169z4ABAygtLfWqRIkQ9bCJiIj4WGVlJWlpacTFxZGZmcnAgV890bGiooLf//73DBs2zMMKJRIU2ERERHwsKiqKoqIiSktLWbNmDRs3bqze9qMf/YjBgwfzrW99y8MKJRI0JCoiIuIjeYUB5q0oZntZOQmxMeRkJTM6PZHY2FiGDBlCfn4+vXv3Zvbs2ezatYtHHnnE65IlAtTDJiIi4hN5hQFuX7yBQFk5Dvho+w6m//Ef5BUGKC8vZ+XKlfTs2ZPHH3+cFStW8Mwzz9CqlX6VtwTqYRMREfGJeSuKKa/46qmLlfs+o+RPDzD+aUf3M05j3LhxjBgxgujoaLp27crFF18MQHZ2Nj//+c+9KlsiQIFNRETEJ7aXldd63yauOwnXPYgBG3OvqG4/dOhQhCsTr6kfNQIWLFhA7969SU1NZf78+V6XIyIiPpUQG9Ogdmk5FNia2MaNG3nsscdYs2YN69evZ9myZWzZssXrskRExIdyspKJaR1Vqy2mdRQ5WckeVSR+ocDWxDZv3sxFF13EaaedRnR0NJdccgl//vOfvS5LRER8aHR6InOy+5AYG4MBibExzMnuw+j0RK9LE49pDlsT6927N3fccQf/93//R0xMDMuXLycjI8PrskRExKdGpycqoMkRFNiaWEpKCjNmzCAzM5P27dvTt29foqP1bRcREZHjp+TQBI5c9HAYb789GYCf/vSnJCUleVyhiIiINCcKbI2satHDqnV0AmXl5Pz+DeBb9DujksWLF/OPf/zD2yJFRESkWVFga2R1Fz0E2Pb8L7jmD/vocXYsCxcu5PTTT/eoOhEREWmOFNgaWd1FDwHOHj8XA9bXWPRQRERE5HhpWY9GpkUPRUREpLEpsDUyLXooIiIijU1Doo2sau2c2neJJmtNHRERETlhCmxNQIseioiISGPSkKiIiIiIzymwiYiIiPicApuIiIiIzymwiYiIiPicbjoQEREJo1u3bnTo0IGoqCiio6NZt26d1yVJC6bAJiIiUo9XX32VM8880+syRDQkKiIiIuJ3CmwiIiJhmBmXX345/fv359FHH/W6HGnhNCQqIiISxptvvklCQgI7d+4kMzOTnj17MnjwYK/LkhZKPWwiIiJAXmGAQbkFdJ/5EoNyC1jziQMgLi6OMWPGsGbNGo8rlJZMgU1ERFq8vMIAty/eQKCsHAds27mb6c/8k7zCAPv37+fll1+md+/eXpcpLZiGREVEpMWbt6KY8orK6veVX5RRsvi/Gf/7VnTr3I5rrrmGYcOGeVihtHQKbCIi0uJtLyuv9b517NkkTHoIA97NvcKbokRq0JCoiIi0eAmxMQ1qF4k0BTYREWnxcrKSiWkdVastpnUUOVnJHlUkUpuGREVEpMUbnZ4IBOeybS8rJyE2hpys5Op2Ea8psImIiBAMbQpo4lcaEhURERHxOQU2EREREZ9TYBMRERHxOQU2ERERaTKTJk0iLi6u1pMiPvvsMzIzM+nRoweZmZns3r3bwwqbBwU2ERERaTITJ04kPz+/Vltubi6XXXYZW7Zs4bLLLiM3N9ej6poPBTYRERFpMoMHD6Zz58612pYsWcKECRMAmDBhAnl5eV6U1qwosImIiEhEffLJJ8THxwMQHx/Pzp07Pa7I/xTYRERERHxOC+eKiIhIo8orDNR6asSEPqfV2n7WWWfx8ccfEx8fz8cff0xcXJxHlTYfEe9hM7NhZlZsZlvNbGaY7dPMbJOZvWNmq8ysa41tlWZWFHotjWzlIiIicix5hQFuX7yBQFk5DgiUlXNffjF7Dhyq3mfkyJEsWrQIgEWLFjFq1CiPqm0+ItrDZmZRwEIgEygF1prZUufcphq7FQIZzrkvzOwmYC5wVWhbuXMuLZI1i4iIyPGbt6KY8orK6ve7ls7l4EcbOFy+h6SkJGbPns3MmTMZN24cTzzxBOeeey7PP/+8hxU3D5EeEh0AbHXOfQBgZs8Co4DqwOace7XG/quBH0S0QhERETlh28vKa73vMnI6AAZ8mHtFdfuqVasiWVazF+kh0URgW433paG2+kwG/lrjfTszW2dmq81sdFMUKCIiIicuITamQe1yfCId2CxMmwu7o9kPgAxgXo3mc51zGcA1wHwzOz/McTeEQt26Xbt2NUbNIiIicpxyspKJaR1Vqy2mdRQ5WckeVXRqiHRgKwXOqfE+Cdhedycz+zZwBzDSOXewqt05tz308QPgNSC97rHOuUedcxnOuYwuXbo0bvUiIiJyVKPTE5mT3YfE2BgMSIyNYU52H0anH21ATY4l0nPY1gI9zKw7EACuJthbVs3M0oFHgGHOuZ012k8HvnDOHTSzM4FBBG9IEBERER8ZnZ6ogNbIIhrYnHOHzOwWYAUQBTzpnHvXzO4G1jnnlhIcAm0PPG9mAB8550YCKcAjZnaYYM9gbp27S0VEREROSeZc2Clkp4SMjAy3bt06r8sQEREROSYzeys0V/8IejSViIiIiM8psImIiIj4nAKbiIiIiM8psImIiIj4nAKbiIiIiM8psImIiIj4nAKbiIiIiM8psImIiIj4nAKbiIiIiM8psImIiIj4nAKbiEgYkyZNIi4ujt69e1e3FRUVcdFFF5GWlkZGRgZr1qzxsEIRaUkU2EREwpg4cSL5+fm12qZPn86sWbMoKiri7rvvZvr06R5VJyItjQKbiEgYgwcPpnPnzrXazIw9e/YA8Pnnn5OQkOBFaSLSAkV7XYCISHMxf/58srKyuO222zh8+DB///vfvS5JRFoI9bCJiBynhx9+mAceeIBt27bxwAMPMHnyZK9LEpEWwpxzXtfQZDIyMty6deu8LkNEmom8wgDzVhSzvaychNgYJvQ5jQdnTGHjxo0AdOrUibKyMswM5xydOnWqHiIVETlZZvaWcy4j3Db1sImIEAxrty/eQKCsHAcEysq5L7+YPQcOVe+TkJDA3/72NwAKCgro0aOHR9WKSEujOWwiIsC8FcWUV1RWv9+1dC4HP9rA4fI9JCUlMXv2bB577DFuvfVWDh06RLt27Xj00Ucb5drbtm3j2muvZceOHbRq1YobbriBW2+9tVHOLSKnBgU2ERFge1l5rfddRgaX7DDgw9wrqtvfeuutRr92dHQ0999/P/369WPv3r3079+fzMxMevXq1ejXEpHmSUOiIiJAQmxMg9obU3x8PP369QOgQ4cOpKSkEAgEmvy6ItJ8KLCJiAA5WcnEtI6q1RbTOoqcrOSI1lFSUkJhYSEDBw6M6HVFxN80JCoiAoxOTwSodZdoTlZydXsk7Nu3j7FjxzJ//nw6duwYseuKiP8psImIhIxOT4xYQKu7hMjUS8/jsTtvZPz48WRnZ0ekBhFpPjQkKiISYXWXECnd/QWTp0yhzRnnMG3aNK/LExEfUmATEYmwukuIHAxsYs+GVRS8WkBaWhppaWksX77cwwpFxG80JCoiEmF1lxBpl5RK1xnLMKCoxhIiIiJV1MMmIhJhXi4hIiLNkwKbiEiE+WUJERFpPjQkKiISYX5YQkREmhcFNhERD0RyCRERaf40JCoiIiLicwpsIiIiIj6nwCYiIiLicwpsIiIiIj6nwCYiIiLicwpsIiIiIj6nwCYiIiLicwpsIiIiIj6nwCbSwm3bto2hQ4eSkpJCamoqCxYsAOCzzz4jMzOTHj16kJmZye7duz2uVESk5VJgE2nhoqOjuf/++9m8eTOrV69m4cKFbNq0idzcXC677DK2bNnCZZddRm5urtelioi0WApsIi1cfHw8/fr1A6BDhw6kpKQQCARYsmQJEyZMAGDChAnk5eV5WaaISIumwCYi1UpKSigsLGTgwIF88sknxMfHA8FQt3PnTo+rExFpuRTYRASAffv2MXbsWObPn0/Hjh29LkdERGqI9roAEYm8vMIA81YUs72snITYGKZeeh6P3Xkj48ePJzs7G4CzzjqLjz/+mPj4eD7++GPi4uI8rlpEpOVSD5tIC5NXGOD2xRsIlJXjgNLdXzB5yhTanHEO06ZNq95v5MiRLFq0CIBFixYxatQojyoWERH1sIm0MPNWFFNeUVn9/mBgE3s2rKJgV3fS0tIAuPfee5k5cybjxo3jiSee4Nxzz+X555/3qmQRkRZPgU2khdleVl7rfbukVLrOWIYBRblX1Nq2atWqCFYmIiL10ZCoSAuTEBvToHYREfGeAptIC5OTlUxM66habTGto8jJSvaoIhERORYNiYq0MKPTEwFq3SWak5Vc3S4iIv6jwCbSAo1OT1RAExFpRiI+JGpmw8ys2My2mtnMMNunmdkmM3vHzFaZWdca2yaY2ZbQa0JkKxcRERHxRkQDm5lFAQuB7wC9gO+bWa86uxUCGc65C4EXgLmhYzsDs4CBwABglpmdHqnaRURERLwS6R62AcBW59wHzrkvgWeBWqtxOudedc59EXq7GkgKfZ4FvOKc+8w5txt4BRgWobpFRJpUWVkZV155JT179iQlJYV//OMfXpckIj4S6cCWCGyr8b401FafycBfG3Ksmd1gZuvMbN2uXbtOslwRkci49dZbGTZsGO+99x7r168nJSXFkzry8/NJTk7mggsuIDc315MaRORIkQ5sFqbNhd3R7AdABjCvIcc65x51zmU45zK6dOlywoWKiETKnj17eP3115k8eTIAbdq0ITY2NuJ1VFZWcvPNN/PXv/6VTZs28cwzz7Bp06aI1yEiR4p0YCsFzqnxPgnYXncnM/s2cAcw0jl3sCHHiog0Nx988AFdunThuuuuIz09nSlTprB///6I17FmzRouuOACzjvvPNq0acPVV1/NkiVLIl6HiBwp0oFtLdDDzLqbWRvgavUBvvoAACAASURBVGBpzR3MLB14hGBY21lj0wrgcjM7PXSzweWhNhGRZu3QoUO8/fbb3HTTTRQWFvK1r33Nk+HIQCDAOed89f/ipKQkAoFAxOsQkSNFNLA55w4BtxAMWpuB55xz75rZ3WY2MrTbPKA98LyZFZnZ0tCxnwG/IBj61gJ3h9pERJqlvMIAg3ILGPPUe0R3OJOP2wTvsbryyit5++23I16Pc0fOUDELNxtFRCIt4gvnOueWA8vrtP28xuffPsqxTwJPNl11IiKRkVcY4PbFGyivqCSq/enQ/gymPfZXuP47FK1aRa9edVc8atpa5q0o5oN3/82Bf65nRGGA0emJlJaWkpCQELE6RKR+epaoiIgH5q0opryisvp952//kMCf72P88G9RVFTET3/604jUURUcA2XltIn/Ovt2buMnT7zC82s+5Nlnn2XkyJHHPomINDk9mkpExAPby8prvW9z1nnET5iPAXm5V0SsjprB0VpF0Tnzh3z0xzv4z2ccd067mdTU1IjVIiL1U2ATEfFAQmwMgTqhrao9kuoGx5jzv0Hi+d/AgDvuiFxwFJGj05CoiIgHcrKSiWkdVastpnUUOVnJEa2jvoAY6eAoIkenwCYi4oHR6YnMye5DYmwMBiTGxjAnuw+j04/28JfG55fgKCJHpyFRERGPjE5PrDegTZo0iWXLlhEXF8fGjRubtAYIzmXbXlZOQmwMOVnJEQ+OInJ0Fm7dnVNFRkaGW7dunddliIg02Ouvv0779u259tprmzSwiYh/mNlbzrmMcNs0JCoi4kODBw+mc+fOXpchIj6hwCYiIiLic5rDJiLiE1VPHKiaSzahz2lelyQiPqHAJiLiAzUfVQUQKCvnvvxtVBw45HFlIuIHCmwiIj5Q91FVAAcPVfLZvoMeVSQifqI5bCIiPlD3iQO7ls5lx+9vo3zXNpKSknjiiSc8qkxE/EA9bCIiPlD3UVVdRk4HggvqvjnzUq/KEhGfUA+biIgP6IkDInI06mETEfEBPXFARI5GgU1ExCeO9qgqEWnZNCQqIiIi4nMKbCIiIiI+p8AmIiIi4nMKbCIiIiI+p8AmIiIi4nMKbCIiIiI+p8AmIiIi4nMKbCIiIiI+p8AmIiIi4nMKbCIiIiI+p8AmIiIi4nMKbCIiIiI+p8AmIiIi4nMKbCIiIiI+p8AmIiIi4nPHHdjMbISZKeCJiIiIRFhDAtgSIGBm95lZSlMVJOKFSZMmERcXR+/evavb7rrrLhITE0lLSyMtLY3ly5d7WKGIiLRkDQls5wOPAuOAjWb2DzO73sw6Nk1pIpEzceJE8vPzj2ifOnUqRUVFFBUVMXz4cA8qExERaUBgc86VOOdmOee6A5nAVuAB4GMz+72ZDW2qIkWa2uDBg+ncubPXZYgctwMHDjBgwAD69u1Lamoqs2bN8rokEWlCJzQnzTlX4Jz7T+DrwFvAeGClmX1oZlPNLLoxi5SG27ZtG0OHDiUlJYXU1FQWLFgAQFFRERdddBFpaWlkZGSwZs0ajyv1t4ceeogLL7yQSZMmsXv3bq/LEanWtm1bCgoKWL9+PUVFReTn57N69WqvyxKRJnJCgc3MLjGzp4BioDewELgceB6YDfyusQqUExMdHc3999/P5s2bWb16NQsXLmTTpk1Mnz6dWbNmUVRUxN1338306dO9LtUTeYUBBuUW0H3mSwzKLSCvMHDEPjfddBP/+te/KCoqIj4+np/85CceVCoSnpnRvn17ACoqKqioqMDMPK5KRJrKcfeEmVlXYELo1Q14DbgBWOycOxjabZWZ/QN4unHLlIaKj48nPj4egA4dOpCSkkIgEMDM2LNnDwCff/45CQkJXpbpibzCALcv3kB5RSUAgbJybl+8gakXxdba76yzzqr+/Prrr2fEiBERrVPkWCorK+nfvz9bt27l5ptvZuDAgV6XJCJNpCFDlx8A24GngCedcx/Ws9+7gMbZfKSkpITCwkIGDhzI/PnzycrK4rbbbuPw4cP8/e9/97q8iJu3org6rFUpr6jkkdc/qNX28ccfV4feP//5z7XuIBXxg6ioKIqKiigrK2PMmDFs3LhRf05FTlENCWzfBfKdc4ePtpNz7n1ANyD4xL59+xg7dizz58+nY8eO/OxnP+OBBx5g7NixPPfcc0yePJmVK1d6XWZEbS8rP6Jt19K5lH60ATu4l6SkJGbPns1rr71GUVERZka3bt145JFHPKhWpLa8wgDzVhSzvaychNgYcrKSGZ2eyJAhQ8jPz1dgk2Zh0qRJLFu2jLi4ODZu3AhATk4Of/nLX2jTpg3nn38+v/3tb4mNjT3GmVoOc855XUOTycjIcOvWrfO6jIip+w/51EvP47E7byQrK4tp06YB0KlTJ8rKyjAznHN06tSpeoi0pRiUW0AgTGhLjI3hzZmXelCRyPGpOZxf+cXnWKsovtahE3cNv4CHpl/HjBkzNHQvzcLrr79O+/btufbaa6sD28svv8yll15KdHQ0M2bMAOC+++7zssyIM7O3nHMZ4bbpyQWniKp/yANl5TigdPcXTJ4yhTZnnFMd1gASEhL429/+BkBBQQE9evTwqGLv5GQlE9M6qlZbTOsocrKSPapI5PjUHM6v3PcZO575Kf965CauG5NJZmamwpo0G+GWUrr88suJjg4O/F100UWUlpZ6UZpvafmNU0TdeVkHA5vYs2EVBbu6k5aWBsC9997LY489xq233sqhQ4do164djz76qFcle2Z0eiJA2GElET+rOZzfJq47Cdc9CIABP//5FR5VJdL4nnzySa666iqvy/AVBbZTRN15We2SUuk6YxkGFOXW/of8rbfeimBl/jQ6PVEBTZqdhNiYsMP5CbExHlQj0jB1p+1M6HNa2P3uueceoqOjGT9+fIQr9DcNiZ4i6vsHW/+Qi5w6NJwvzVXdaTuBsnLuyy9mz4FDtfZbtGgRy5Yt4w9/+IPWFaxDge0UoX/IRU59o9MTmZPdh8TYGIzgjTJzsvuot1h8L9xySgcPVfLpvoPV7/Pz87nvvvtYunQpp50WvvetJdOQ6ClC87JEWgYN50tzVHfazq6lczn40QYqy/dUL6U0Z84cDh48SGZmJhC88eA3v/mNF+X6kpb1EBERkSal5ZSOj5b1EBEREc9o2s7Ji3hgM7NhZlZsZlvNbGaY7YPN7G0zO2RmV9bZVmlmRaHX0shVLSIiIidK8y9PXkTnsJlZFLAQyARKgbVmttQ5t6nGbh8BE4Hbwpyi3DmX1uSFioiISKPS/MuTE+mbDgYAW51zHwCY2bPAKKA6sDnnSkLbjvrMUhEREZGWItJDoonAthrvS0Ntx6udma0zs9VmNjrcDmZ2Q2ifdbt27TqZWkVERER8IdKBLdwqeA25TfXc0N0T1wDzzez8I07m3KPOuQznXEaXLl1OtE4RERER34h0YCsFzqnxPgnYfrwHO+e2hz5+ALwGpDdmcSIiIiJ+FOnAthboYWbdzawNcDVwXHd7mtnpZtY29PmZwCBqzH0TEREROVVFNLA55w4BtwArgM3Ac865d83sbjMbCWBm3zCzUuB7wCNm9m7o8BRgnZmtB14FcuvcXSoiIiJyStKTDkRERER8QE86EBHxkW3btjF06FBSUlJITU1lwYIFADz//POkpqbSqlUr9J9NEalJD38XEYmw6Oho7r//fvr168fevXvp378/mZmZ9O7dm8WLF3PjjTd6XaKI+IwCm4hIhMXHxxMfHw9Ahw4dSElJIRAIkJmZ6XFlIuJXGhIVEfFQSUkJhYWFDBw40OtSRMTHFNhERDyyb98+xo4dy/z58+nYsaPX5YiIj2lIVEQkAvIKA8xbUcz2snISYmOYeul5PHbnjYwfP57s7GyvyxMRn1MPm4hIE8srDHD74g0EyspxQOnuL5g8ZQptzjiHadOmeV2eiDQD6mETEWli81YUU15RWf3+YGATezasomBXd9LS0gC49957OXjwID/+8Y/ZtWsXV1xxBWlpaaxYscKrskXERxTYRESa2Pay8lrv2yWl0nXGMgwoyr2i1rYxY8ZEsDIRaS40JCoi0sQSYmMa1C4iUpcCm4hIE8vJSiamdVSttpjWUeRkJXtUkYg0NxoSFRFpYqPTEwFq3SWak5Vc3S4iciwKbCIiETA6PVEBTUROmIZERURERHxOgU1EGs22bdsYOnQoKSkppKamsmDBAgDuuusuEhMTSUtLIy0tjeXLl3tcqYhI86IhURFpNNHR0dx///3069ePvXv30r9//+oHmk+dOpXbbrvN4wpFRJonBTYRaTTx8fHEx8cD0KFDB1JSUggEAh5XJSLS/GlIVESaRElJCYWFhQwcOBCAhx56iAsvvJBJkyaxe/duj6sTEWleFNhEpNHt27ePsWPHMn/+fDp27MhNN93Ev/71L4qKioiPj+cnP/mJ1yWKiDQrGhIVkZOSVxiotb7Y1EvP47E7b2T8+PFkZ2cDcNZZZ1Xvf/311zNixAivyhURaZbUwyYiJyyvMMDtizcQKCvHAaW7v2DylCm0OeMcpk2bVr3fxx9/XP35n//8Z3r37u1BtSIizZd62ETkhM1bUUx5RWX1+4OBTezZsIqCXd1JS0sD4N577+WZZ56hqKgIM6Nbt2488sgjXpUsItIsKbCJyAnbXlZe6327pFS6zliGAUW5V1S3Dx8+PMKViYicWjQkKiInLCE2pkHtIiJyYhTYROSE5WQlE9M6qlZbTOsocrKSPapIROTUpCFRETlhVQ8zr3mXaE5Wsh5yLiLSyBTYROSkjE5PVEATEWliGhIVERER8TkFNhERERGfU2ATERER8TkFNhERERGfU2ATERER8TkFNhERERGfU2ATERER8TkFNhERERGfU2ATERER8TkFNhERERGfU2ATERER8TkFNpEIKi4uJi0trfrVsWNH5s+f73VZIiLic3r4u0gEJScnU1RUBEBlZSWJiYmMGTPG46pERMTv1MMmElJZWUl6ejojRoyIyPVWrVrF+eefT9euXSNyPRGBbdu2MXToUFJSUkhNTWXBggUArF+/nosvvpg+ffrw3e9+lz179nhcqUhtCmwiIQsWLCAlJSVi13v22Wf5/ve/H7HriQhER0dz//33s3nzZlavXs3ChQvZtGkTU6ZMITc3lw0bNjBmzBjmzZvndakitSiwiQClpaW89NJLTJkypdHPnVcYYFBuAd1nvsSg3ALyCgN8+eWXLF26lO9973uNfj0RqV98fDz9+vUDoEOHDqSkpBAIBCguLmbw4MEAZGZm8uKLL3pZpsgRFNhEgP/3//4fc+fOpVWrxv0rkVcY4PbFGwiUleOAQFk5ty/ewKyFT9OvXz/OOuusRr2eiBy/kpISCgsLGThwIL1792bp0qUAPP/882zbts3j6kRqU2CTFm/ZsmXExcXRv3//Rj/3vBXFlFdU1morr6jksad+r+FQaVHqmzsG8Otf/5rk5GRSU1OZPn16o187XC/3vn37GDt2LPPnz6djx448+eSTLFy4kP79+7N3717atGnT6HWInAzdJSotVl5hgHkrinl3ySLKN73GC3l/odXhCvbs2cMPfvADnn766ZO+xvay8iPaDlccYPf7b5GdnXfS5xdpLqrmjvXr14+9e/fSv39/MjMz+eSTT1iyZAnvvPMObdu2ZefOnY163ape7qr/OAXKypn5fCExr/6S/xw/nuzsbAB69uzJyy+/DMD777/PSy+91Kh1iJwsBTZpkWr+Ix57yURiL5lITOsoxp+7l9VLFjVKWANIiI0hUCe0tWrdjotm5dGpU6dGuYZIcxAfH098fDxQe+7YY489xsyZM2nbti0AcXFxjXrdur3czjlKl/6Kjp3OYNq0adXtO3fuJC4ujsOHD/Pf//3f/PCHP2zUOkROloZEpUWqb6jy2bWNO28lJyuZmNZRtdpiWkeRk5XcqNcRaU5qzh17//33eeONNxg4cCCXXHIJa9eubdRr1e3lPhjYxP53X+XTLW9XL2C9fPlynnnmGb7+9a/Ts2dPEhISuO666xq1DpGTpR62FmjSpEnV87Y2btwIwJ133smSJUto1aoVcXFxPPXUUyQkJES0rm3btnHttdeyY8cOWrVqxQ033MCtt97KVVddRXFxMQBlZWXExsZWLz57osINVQLs75zMskenhd12IkanJwLBgLi9rJyE2BhyspKr20Vamrpzxw4dOsTu3btZvXo1a9euZdy4cXzwwQeYWaNcr24vd7ukVLrOWEZibAxvzry01r633npro1xTpCkosLVAEydO5JZbbuHaa6+tbsvJyeEXv/gFAA8++CB33303v/nNbyJaV31zXP70pz9V7/OTn/ykUYYSww1VVrU3ttHpiQpo0iJVzROt+s/K1EvP47E7b2R8jbljSUlJZGdnY2YMGDCAVq1a8emnn9KlS5dGqSEnK7nWHDZQL7c0TxEfEjWzYWZWbGZbzWxmmO2DzextMztkZlfW2TbBzLaEXhMiV/WpZfDgwXTu3LlWW8eOHas/379/f6P977Yh6lsfqYpzjueee65R7q7UUKXIV+q7gzMnJ4eePXty4YUXMmbMGMrKyo77nHWXtCnd/QWTp0yhzRnn1Jo7Nnr0aAoKCoDgZP8vv/ySM888s9G+ttHpiczJ7kNibAwGJMbGMCe7j/4TJc1ORHvYzCwKWAhkAqXAWjNb6pzbVGO3j4CJwG11ju0MzAIyAAe8FTp2dyRqbwnuuOMOfve739GpUydeffVVT2upOcelyhtvvMFZZ51Fjx49Tvr8GqoU+Up9vduZmZnMmTOH6OhoZsyYwZw5c7jvvvuO65x154keDGxiz4ZVFOzqTlpaGgD33nsvkyZNYtKkSfTu3Zs2bdqwaNGiRv8Po3q55VQQ6SHRAcBW59wHAGb2LDAKqA5szrmS0LbDdY7NAl5xzn0W2v4KMAx4punLbv7qDk1M6HPaEfvcc8893HPPPcyZM4eHHnqI2bNne1DpkXNcqjzzzDONunaZ/hEXCarvDs7LL7+8ep+LLrqIF1544bjPWXeeaNXcMQOKcq+ota2x7soWOZVFekg0Eah5G15pqK2pj23Rwq22f19+MXsOHAq7/zXXXFPvY1kOHDjAgAED6Nu3L6mpqcyaNQuAhx56iAsuuAAz49NPP21wfVWLWl58z8t8K3NErTkuAIcOHWLx4sVcddVVDTq3iDRMuN5tgCeffJLvfOc7x32e+uaDNsU8UZGWINKBLVw/t2vMY83sBjNbZ2brdu3a1aDiTlXhlrA4eKiST/cdrH6/ZcuW6s+XLl1Kz549w56rbdu2FBQUsH79eoqKisjPz2f16tUMGjSIlStX0rVr1wbVVjNMHnaODc/k8u/DsZw3tHYwW7lyJT179iQpKalB5xeR41df7/Y999xDdHQ048ePP+5zaZ6oSOOK9JBoKXBOjfdJwPYGHDukzrGv1d3JOfco8ChARkbG8YbBU1rdoYldS+dy8KMNVJbvISkpidmzZ7N8+XKKi4tp1aoVXbt2rfcOUTOjffv2AFRUVFBRUYGZkZ6efkK11QyTVesjfdmlG+OvuIQece259957GT58OM8++6we5STSiI7nDk6ARYsWsWzZMlatWtWguWWaJyrSuMy5yGUaM4sG3gcuAwLAWuAa59y7YfZ9CljmnHsh9L4z8BbQL7TL20D/qjlt4WRkZLh169Y16tfQHA3KLQi7hEW4dYiOR2VlJf3792fr1q3cfPPNtSYhd+vWjXXr1h33XV7dZ74UtovVgA/rzHMRkcZR93FNzjnK/jqfwb278Zc/Pl69X35+PtOmTeNvf/tboy2zISL1M7O3nHMZ4bZFdEjUOXcIuAVYAWwGnnPOvWtmd5vZSAAz+4aZlQLfAx4xs3dDx34G/IJgyFsL3H20sCZfaeyhiaioKIqKiigtLWXNmjXVi++eCM1zEYm8eu/gfLWg1ur/t9xyC3v37iUzM5O0tDQ9rknEQxFfONc5txxYXqft5zU+X0twuDPcsU8CTzZpgaegkx2aqDt0UnVsbGwsQ4YMIT8/n969e59QbVrUUiTyjvcOzuHDh0e4MhGpj5500EKc6BIWdYdOPtq+g+l//Ay4mKyenVm5ciUzZsw4qbpA81xEIimST/oQkcahwCZHVXfopHLfZ5T86QHGP+3ofsZpjBs3jhEjRvDggw8yd+5cduzYwYUXXsjw4cN5/PHHj3Lmr2g9NJHIUs+2SPMT0ZsOIk03HZw83RQgcmqqb6qDiHjnaDcdqIdNjkpDJyKnJvVsizQvEX/4u/hDfQ97rvLLX/4SM+PGAV20+KWIiIjH1MPWQtX3sOdevXqxbds2XnnlFc4991yGXxhPx9M7a+hERETEQwpsLVR9D3vu1asXU6dOZe7cuYwaNQrQ0ImIiIjXNCQqtR72vHTpUhITE+nbt6/XZYmIiEiIethauJoPe46Ojuaee+7h5Zdf9rosERERqUGBrQU51sOeN2zYwIcffljdu1ZaWkq/fv1Ys2YNZ599tsfVi4iItFxah62FON6HPdfU0Ae5i4iIyInzzcPfxTvH+7BnERER8R8NibYQx/uw55pKSkqavjCRFmzbtm1ce+217Nixg1atWnHDDTdw6623cuedd7JkyRJatWpFXFwcTz31FAkJCV6XKyIeUg9bC1Hfkwn0xAIR71Sth7h582ZWr17NwoUL2bRpEzk5ObzzzjsUFRUxYsQI7r77bq9LFRGPKbC1EDlZyXpigYjPxMfH069fP6D2eogdO3as3mf//v2YmVcliohPaEi0haha+FZPLBDxp5rrIQLccccd/O53v6NTp068+uqrHlcnIl7TXaIiIh7bt28fl1xyCXfccQfZ2dm1ts2ZM4cDBw4we/Zsj6oTkUjRXaIiIj6RVxhgUG4B3We+xKDcAl5YU8LYsWOr10Os65prruHFF1/0oFIR8RMFNhGRCKlaDzFQVo4DSnd/weQpU2hzxjlMmzater8tW7ZUf7506VJ69uzpQbUi4ieawyYiEiH1roe4qztpaWkA3HvvvTzxxBMUFxfTqlUrunbtym9+8xuvShYRn1BgExGJkONdD3H48OERrkxE/E5DoiIiEaL1EEXkRCmwRcDAgQOJjo6mXbt2fP/73+fAgQPV2375y19iZnz66aceVigikaD1EEXkRCmwNbFAIMBHH33E66+/zgUXXEBlZSXPPvssEHwszSuvvMK5557rcZUiEgmj0xOZk92HxNgYDEiMjWFOdh+thygix6Q5bBEQHR3NaaedBsAXX3xR/UzAqVOnMnfuXEaNGuVleSISQaPTExXQRKTBFNiaWGJiIrfddhv/8R//wZdffknfvn25/PLLWbp0KYmJifTt29frEkVERMTnFNiaQF5hoPoRUHFtD/HF8ud44403uPbaa9m/fz9PPPEEjz76KC+//LLXpYqIiEgzoDlsjSyvMEDO8+urF8b8YP1q/v3l13hrRwVmRnZ2Ni+//DIffvghffv2pVu3bpSWltKvXz927NjhdfkiIiLiQwpsjeyupe9Scfir57NGd+zCgUAxv1q+AYBVq1bxzW9+k507d1JSUkJJSQlJSUm8/fbbnH322V6VLSIiIj6mIdFGVlZeUet924RkMCh++IfgDvPhhx9y8cUXe1SdiIiINEcKbBGQMPl/ACipsZJ5TSUlJRGsRkRERJobDYk2stNPa92gdhEREZFjUWBrZLO+m0rrKKvV1jrKmPXdVI8qEhERkeZOQ6KNrGpBzKplPRJiY8jJStZCmSIiInLCFNiagFYyFxERkcakIdEmduDAAQYMGEDfvn1JTU1l1qxZAHz44YcMHDiQHj16cNVVV/Hll196XKmIiIj4lQJbE2vbti0FBQWsX7+eoqIi8vPzWb16NTNmzGDq1Kls2bKF008/nSeeeMLrUkVERMSnFNiamJnRvn17ACoqKqioCD7xoKCggCuvvBKACRMmkJeX52WZIiIi4mMKbBFQWVlJWloacXFxZGZmcv755xMbG0t0dHAKYVJSEoFAwOMqRURExK9000ETqPnw96q7RIuKiigrK2PMmDFs3rz5iGPMLMyZRERERBTYGl1eYYDbF2+gvKISgEBZObcvDj5HdHR6IkOGDGH16tWUlZVx6NAhoqOjKS0tJSEhwcuyRURExMc0JNrI5q0org5rAJVffM7+vZ8H28vLWblyJSkpKQwdOpQXXngBgEWLFjFq1CivShYRERGfUw9bI9teVl7rfeW+z/j0pQfY4Q7zjae/xrhx4xgxYgS9evXi6quv5mc/+xnp6elMnjzZo4pFRETE7xTYGllCbAyBGqGtTVx3Eq57kMTYGN6ceWl1+3nnnceaNWu8KFFERESaGQ2JNrKcrGRiWkfVaotpHUVOVrJHFYmIiEhzpx62RqZniYqIiEhjU2BrAnqWqIiIiDQmDYmKiIiI+JwCm4iIiIjPKbCJiIiI+FzEA5uZDTOzYjPbamYzw2xva2Z/Cm3/p5l1C7V3M7NyMysKvX4T6dpFREREvBDRmw7MLApYCGT+//buP7au+rzj+PshKZCtKBnEMMUGko0MQZzNUT00NM0S7aRQRYQE0UI0SgKhUaRmRWpECxqTJoaUULTxx5ZKIKVTVwmFQPlhVVqo1HSbVmUM0xSiUJkZyMDJ+LGGEEUNdA7P/vAlc4yDL/j6nK/t9+uve7/nXPuTPHL8yTn33AMMAs9GRG9mvjhit/XAO5l5SUTcCNwH3NDY9nJmdlWZWZIkqW5VH2G7AhjIzFcy89fADmD0PZmuBb7XePwY8IXwzuiSJGkGq7qwtQOvj3g+2Fgbc5/MHALeBc5rbFsUEXsj4l8i4k8mO6wkSVIJqv4ctrGOlGWT+/w3cFFm/jIiPgc8GRFLMvPoKS+O2ABsALjoootaEFmSJKleVR9hGwQuHPG8Azh0un0iYjYwFzicme9n5i8BMvM54GXgBuOeXgAACvFJREFU90Z/g8x8KDO7M7O7ra1tEv4IkiRJ1aq6sD0LLI6IRRFxJnAj0Dtqn15gbePx9cDuzMyIaGtctEBE/A6wGHilotySJEm1qfSUaGYORcQm4GlgFvDdzNwfEfcAfZnZC2wHvh8RA8BhhksdQA9wT0QMASeAjZl5uMr8kiRJdYjM0W8hmz66u7uzr6+v7hiSJEnjiojnMrN7rG3e6UCSJKlwFjZJkqTCWdgkSZIKZ2GTJEkqnIVNkiSpcBY2SZKkwlnYJEmSCmdhkyRJKpyFTZIkqXAWNkmSpMJZ2CRJkgpnYZMkSSqchU2SJKlwFjZJkqTCWdgkSZIKZ2GTJEkqnIVNkiSpcBY2SZKkwlnYJEmSCmdhkyRJKpyFTZIkqXAWNkmSpMJZ2CRJkgpnYZMkSSqchU2SJKlwFjZJkqTCWdgqdOutt3L++efT2dl5cu2GG26gq6uLrq4uFi5cSFdXV40JJUlSiWbXHWAmWbduHZs2beLmm28+ufbII4+cfLx582bmzp1bRzRJklQwC1uFenp6OHDgwJjbMpOdO3eye/fuakNJkqTieUq0AmOdCn3++ee58sorWbp0Kddccw27du3iggsuYPHixTUmlSRJJbKwVWDdunXs2rXrlLXbbruNrVu3sm/fPlavXs3dd9/NmjVrakooSZJK5inRSfTk3oPc/3Q/h44c59wc5Oh7Qye39ff309PTA8BVV13Fhg0beOqpp+qKKkmSCuYRtkny5N6D3PX4Pg4eOU4Cbx59jzePvseP9r8BQGdnJ729vQBs2bIFgI6OjrriSpKkgkVm1p1h0nR3d2dfX1/l3/fJvQfZvPN5Toz4ux16900O/cOfM/vMs8njRzn33HOZP38+Z599NidOnGBgYIBjx45VnlWSJJUhIp7LzO6xtnlKtMU+PLJ2YowiPPuc+bSv/w6vbl1xyvpLL73ETTfdVFVESZI0xXhKtMXuf7qf4/974rTbF8ybA8Bbb70FwAcffMC9997Lxo0bK8knSZKmHo+wtdihI8c/svZ277d5/7V9nDh+lP4H/oztbfdy7Ngxtm3bBsB1113HLbfcUnVUSZI0RVjYWmzBvDkcHFXa2lZ+k1kR/M2X/4BVy9pPrt9+++1Vx5MkSVOQp0Rb7I7llzLnM7NOWZvzmVkfKWuSJEnN8ghbi31Yyj78/LUF8+Zwx/JLLWuSJOlT8wjbJFi1rJ2f3vl5Xt26gp/e+Xl6/+4vP3JrqkcffZQlS5ZwxhlnUMdHj0iSpKnDwlaBsW5N1dnZyeOPP37ybgeSJEmn4ynRCvT09HDgwIFT1i677LJ6wkiSpCnHI2ySJEmFs7BJkiQVzlOik+DJvQc/cpVo12/VnUqSJE1VHmFrsQ/vJXrwyHESOHjkOHc9vo8f7X+j7miSJGmKsrC12Fj3En3tB1vYtGYF/f39dHR0sH37dp544gk6OjrYs2cPK1asYPny5TUlliRJpfOUaIuNdS/RtpXfJIBXt644ZX316tUVpZIkSVOZR9habMG8OZ9oXZIkaTyVF7aIuDoi+iNiICLuHGP7WRHxSGP7MxGxcMS2uxrr/RFR5DnE091L9I7ll9aUSJIkTXWVFraImAVsA74IXA6siYjLR+22HngnMy8BHgDua7z2cuBGYAlwNfCdxtcryqpl7Wy5bint8+YQQPu8OWy5bqn3EpUkSZ9a1e9huwIYyMxXACJiB3At8OKIfa4F/qrx+DHg7yMiGus7MvN94NWIGGh8vT0VZW/aqmXtFjRJktQyVZ8SbQdeH/F8sLE25j6ZOQS8C5zX5GslSZKmnaoLW4yxlk3u08xriYgNEdEXEX1vv/32p4goSZJUlqoL2yBw4YjnHcCh0+0TEbOBucDhJl9LZj6Umd2Z2d3W1tbC6JIkSfWourA9CyyOiEURcSbDFxH0jtqnF1jbeHw9sDszs7F+Y+Mq0kXAYuA/KsotSZJUm0ovOsjMoYjYBDwNzAK+m5n7I+IeoC8ze4HtwPcbFxUcZrjU0dhvJ8MXKAwBX8vME2N+I0mSpGkkhg9eTU/d3d3Z19dXdwxJkqRxRcRzmdk91jbvdCBJklQ4C5skSVLhLGySJEmFs7BJkiQVzsImSZJUOAubJElS4SxskiRJhbOwSZIkFc7CJkmSVDgLmyRJUuEsbJIkSYWzsEmSJBXOwiZJklQ4C5skSVLhLGySJEmFs7BJkiQVzsImSZJUuMjMujNMmoh4G/ivGiPMB/6nxu+vajnvmcNZzxzOeuYoYdYXZ2bbWBumdWGrW0T0ZWZ33TlUDec9czjrmcNZzxylz9pTopIkSYWzsEmSJBXOwja5Hqo7gCrlvGcOZz1zOOuZo+hZ+x42SZKkwnmETZIkqXAWthaIiKsjoj8iBiLizjG2nxURjzS2PxMRC6tPqVZoYtY9EfGziBiKiOvryKjWaWLe34iIFyPihYj4cURcXEdOTVwTs94YEfsi4ucR8W8RcXkdOTVx4816xH7XR0RGRBFXjlrYJigiZgHbgC8ClwNrxvhBXg+8k5mXAA8A91WbUq3Q5KxfA9YBD1ebTq3W5Lz3At2Z+fvAY8C3q02pVmhy1g9n5tLM7GJ4zn9bcUy1QJOzJiLOAb4OPFNtwtOzsE3cFcBAZr6Smb8GdgDXjtrnWuB7jcePAV+IiKgwo1pj3Fln5oHMfAH4oI6Aaqlm5v2TzPxV4+m/Ax0VZ1RrNDProyOe/ibgG8CnpmZ+ZwP8NcPF/L0qw30cC9vEtQOvj3g+2Fgbc5/MHALeBc6rJJ1aqZlZa/r4pPNeD/zTpCbSZGlq1hHxtYh4meFf5F+vKJtaa9xZR8Qy4MLM/GGVwcZjYZu4sY6Ujf6fVzP7qHzOcWZpet4RcRPQDdw/qYk0WZqadWZuy8zfBb4F3D3pqTQZPnbWEXEGw29d2lxZoiZZ2CZuELhwxPMO4NDp9omI2cBc4HAl6dRKzcxa00dT846IPwX+AliZme9XlE2t9Ul/tncAqyY1kSbLeLM+B+gE/jkiDgB/BPSWcOGBhW3ingUWR8SiiDgTuBHoHbVPL7C28fh6YHf6AXhTUTOz1vQx7rwbp04eZLisvVVDRrVGM7NePOLpCuA/K8yn1vnYWWfmu5k5PzMXZuZCht+bujIz++qJ+/8sbBPUeE/aJuBp4BfAzszcHxH3RMTKxm7bgfMiYgD4BnDay4hVrmZmHRF/GBGDwJeAByNif32JNRFN/mzfD3wWeLTxcQ8W+CmoyVlvioj9EfFzhv8dX3uaL6eCNTnrInmnA0mSpMJ5hE2SJKlwFjZJkqTCWdgkSZIKZ2GTJEkqnIVNkiSpcBY2SZKkwlnYJEmSCmdhkyRJKpyFTZLGERHzImIwIv5x1HpvRLwUEb9RVzZJM4OFTZLGkZlHgPXAVyJiFUBE3MLwPSXXZeav6swnafrz1lSS1KSIeBBYBVwN/AR4MDO/VW8qSTOBhU2SmhQRnwVeABYAA8DnMvP9elNJmgk8JSpJTcrMY8APgbOA7ZY1SVXxCJskNSkiuoE9wD7gYmBJZr5RbypJM4GFTZKaEBFnAz8DXgG+DDwP/CIzV9YaTNKM4ClRSWrOvcBvA19tXBW6FlgREetqTSVpRvAImySNIyL+GPhX4CuZ+fCI9fuBrwKdmTlYVz5J05+FTZIkqXCeEpUkSSqchU2SJKlwFjZJkqTCWdgkSZIKZ2GTJEkqnIVNkiSpcBY2SZKkwlnYJEmSCmdhkyRJKtz/Ab7fCTIw4PuqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from networkx import karate_club_graph, to_numpy_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if False:\n",
    "    # Raw Data Plot\n",
    "    import networkx as nx\n",
    "    G = nx.karate_club_graph()\n",
    "    print(\"Node Degree\")\n",
    "    for v in G:\n",
    "        print('%s %s' % (v, G.degree(v)))\n",
    "    nx.draw_circular(G, with_labels=True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ---- Main GCN below -------#\n",
    "zkc = karate_club_graph()\n",
    "print(zkc.name)\n",
    "\n",
    "order = sorted(list(zkc.nodes()))\n",
    "A = to_numpy_matrix(zkc, nodelist=order)\n",
    "I = np.eye(zkc.number_of_nodes())\n",
    "A_hat = A + I  #with node itself in the neighborhood\n",
    "\n",
    "D_hat = np.array(np.sum(A_hat, axis=0))[0]\n",
    "D_hat = np.matrix(np.diag(D_hat))\n",
    "\n",
    "print(f'A={A}')\n",
    "print(f'D_hat={D_hat}')\n",
    "\n",
    "# Weight initialize\n",
    "W_1 = np.random.normal(\n",
    "    loc=0, scale=1, size=(zkc.number_of_nodes(), 4))  #(xx,4)\n",
    "W_2 = np.random.normal(\n",
    "    loc=0, size=(W_1.shape[1], 2))   #(xx,2)\n",
    "\n",
    "'''\n",
    "Stack the GCN layers. We here use just the identity matrix as feature representation, \n",
    "that is, each node is represented as a one-hot encoded categorical variable.\n",
    "'''\n",
    "def gcn_layer(A_hat, D_hat, X, W):\n",
    "    tmp = D_hat**-1 * A_hat * X * W\n",
    "    return (abs(tmp) + tmp) / 2 #BW: aka ReLU\n",
    "\n",
    "H_1 = gcn_layer(A_hat, D_hat, I, W_1)\n",
    "H_2 = gcn_layer(A_hat, D_hat, H_1, W_2)\n",
    "output = H_2\n",
    "\n",
    "# Extract the feature representations\n",
    "feature_representations = {\n",
    "    node: np.array(output)[node] \n",
    "    for node in zkc.nodes()}\n",
    "print(feature_representations)\n",
    "\n",
    "# Plot the leared feature representations\n",
    "def plot_dict_values(dict_to_plot):\n",
    "    fig, ax = plt.subplots()\n",
    "    x, y = zip(*dict_to_plot.values())  # ☆☆☆ Revised from: key_lists, value_lists = zip(*lists)\n",
    "    ax.scatter(x, y)\n",
    "\n",
    "    ax.set_xlabel('x', fontsize=20)\n",
    "    ax.set_ylabel('y', fontsize=20)\n",
    "    ax.set_title('Zachary Karate Club')\n",
    "    ax.grid(True)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the leared feature representations\n",
    "xs, ys = zip(*feature_representations.values()) # ☆☆☆\n",
    "labels = feature_representations.keys()    \n",
    "# Show\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Zachary Karate Club', fontsize=20)\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('y', fontsize=15)\n",
    "plt.scatter(xs, ys, marker = 'o')\n",
    "for label, x, y in zip(labels, xs, ys):  # ☆☆☆\n",
    "    plt.annotate(label, xy = (x, y))     # ☆☆☆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 👆BW: I should note that for this example the randomly initialized weights were very likely to give 0 values on either the x- or the y-axis as result of the ReLU function, so it took a few random initializations to produce the figure above.\n",
    "\n",
    "+ A recent paper by Kipf and Welling proposes fast approximate **spectral graph convolutions** using a spectral propagation rule (more general):\n",
    " \\begin{equation}\n",
    "    f(X, A)=\\sigma\\left(\\mathbf{D}^{-0.5} \\hat{\\mathbf{A}} \\mathbf{D}^{-0.5} \\mathbf{X} \\mathbf{W}\\right)\n",
    " \\end{equation}\n",
    "\n",
    "### Short Conclusion\n",
    "###### We saw how we can build these networks using numpy and how powerful they are: even randomly initialized GCNs can separate communities in Zachary’s Karate Club based on the adjacency matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5++ Normalized Adjacency and Laplacian Matrices\n",
    "##### ref: [ORIE 6334 Spectral Graph Theory, Lecture 7, 2016](./img/Spectral_Graph_Theory.pdf)\n",
    "\n",
    "1. **Definition 1** The normalized adjacency matrix is\n",
    "    \\begin{equation}\n",
    "    \\mathscr{A} \\equiv D^{-1 / 2} A D^{-1 / 2}\n",
    "    \\end{equation}\n",
    "  where $A$ is the adjacency matrix of $G$ and $D = diag(d)$ for $d(i)$ the degree of node $i$. For a graph $G$ (with no isolated vertices), we can see that:\n",
    "   \\begin{equation}\n",
    "    D^{-1 / 2}=\\left(\\begin{array}{cccc}\n",
    "    \\frac{1}{\\sqrt{d(1)}} & 0 & \\cdots & 0 \\\\\n",
    "    0 & \\frac{1}{\\sqrt{d(2)}} & \\cdots & 0 \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    0 & 0 & \\cdots & \\frac{1}{\\sqrt{d(n)}}\n",
    "    \\end{array}\\right)\n",
    "   \\end{equation}\n",
    "\n",
    "2. **Definition 2** The normalized Laplacian matrix is:\n",
    "    \\begin{equation}\n",
    "    \\begin{array}{c}\n",
    "    \\mathscr{L} \\equiv I-\\mathscr{A} \\\\\n",
    "    \\mathscr{L}=I-\\mathscr{A}=D^{-1 / 2}(D-A) D^{-1 / 2}=D^{-1 / 2} L_{G} D^{-1 / 2}\n",
    "    \\end{array}\n",
    "    \\end{equation}\n",
    "  where $L_{G}$ the (unnormalized) Laplacian. “Normalizing” the adjacency matrix makes its largest eigenvalue equal 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5+++ Aggregation as a Weighted Sum (c\\*A\\*X)\n",
    "\n",
    "We can understand the aggregation functions I’ve presented thus far as weighted sums where each aggregation rule differ only in their choice of weights. We’ll first see how we can express the relatively simple sum and mean rules as weighted sums before moving on to the spectral rule.\n",
    "\n",
    "1. The Sum Rule as a Weighted Sum\n",
    "\n",
    "To see how the aggregate feature representation of the ith node is computed using the sum rule, we see how the ith row in the aggregate is computed.\n",
    "  \\begin{equation}\n",
    "    \\begin{aligned}\n",
    "    \\operatorname{aggregate}(\\mathbf{A}, \\mathbf{X})_{i} &=\\mathbf{A}_{i} \\mathbf{X} \\\\\n",
    "    &=\\sum_{j=1}^{N} A_{i, j} \\mathbf{X}_{j}\n",
    "    \\end{aligned}\n",
    " \\end{equation}\n",
    " We can compute the aggregate feature representation of the ith node as a vector-matrix product. We can formulate this vector-matrix product as a simple weighted sum.\n",
    "\n",
    "2. The Mean Rule as a Weighted Sum\n",
    "\n",
    "To see how the mean rule aggregates node representations, we again see how the ith row in the aggregate is computed, now using the mean rule. For simplicity, we only consider the mean rule on the “raw“ adjacency matrix without addition between A and the identity matrix I which simply corresponds to adding self-loops to the graph.\n",
    " \\begin{equation}\n",
    "    \\begin{aligned}\n",
    "    \\operatorname{aggregate}(\\mathbf{A}, \\mathbf{X})_{i} &=\\mathbf{D}^{-1} \\mathbf{A}_{i} \\mathbf{X} \\\\\n",
    "    &=\\sum_{k=1}^{N} D_{i, k}^{-1} \\sum_{j=1}^{N} A_{i, j} \\mathbf{X}_{j} \\\\\n",
    "    &=\\sum_{j=1}^{N} D_{i, i}^{-1} A_{i, j} \\mathbf{X}_{j} \\\\\n",
    "    &=\\sum_{j=1}^{N} \\frac{1}{D_{i, i}} A_{i, j} \\mathbf{X}_{j} \\\\\n",
    "    &=\\sum_{j=1}^{N} \\frac{A_{i, j}}{D_{i, i}} \\mathbf{X}_{j}\n",
    " \\end{aligned}\n",
    " \\end{equation}\n",
    " ☆ Whereas the sum rule depends solely on the neighborhood defined by the adjacency matrix A, the mean rule also depends on node degrees.\n",
    " \n",
    "3. The Spectral Rule as a Weighted Sum\n",
    "\n",
    "We now have a useful framework in place to analyse the spectral rule. Let’s see where it takes us!\n",
    "    \\begin{equation}\n",
    "    \\begin{aligned}\n",
    "        \\operatorname{aggregate}(\\mathbf{A}, \\mathbf{X})_{i} &=\\mathbf{D}^{-0.5} \\mathbf{A}_{i} \\mathbf{D}^{-0.5} \\mathbf{X} \\\\\n",
    "        &=\\sum_{k=1}^{N} D_{i, k}^{-0.5} \\sum_{j=1}^{N} A_{i, j} \\sum_{l=1}^{N} D_{j, l}^{-0.5} \\mathbf{X}_{j} \\\\\n",
    "        &=\\sum_{j=1}^{N} D_{i, i}^{-0.5} A_{i, j} D_{j, j}^{-0.5} \\mathbf{X}_{j} \\\\\n",
    "        &=\\sum_{j=1}^{N} \\frac{1}{D_{i, i}^{0.5}} A_{i, j} \\frac{1}{D_{j, j}^{0.5}} \\mathbf{X}_{j}\n",
    "    \\end{aligned}\n",
    "    \\end{equation}\n",
    "    \n",
    " ☆  When computing the aggregate feature representation of the ith node, we not only take into consideration the degree of the ith node, but also the degree of the jth node.\n",
    " \n",
    " ☆ Similar to the mean rule, the spectral rule normalizes the aggregate **s.t.(subject to)** the aggregated feature representation remains roughly on the same scale as the input features. However, the spectral rule weighs neighbor in the weighted sum higher if they have a low-degree and lower if they have a high-degree. This may be useful when low-degree neighbors provide more useful information than high-degree neighbors.\n",
    "\n",
    "### 1.5-TBD: Semi-Supervised Classification with GCNs\n",
    "###### ref: https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Graph Convolutional Networks\n",
    "1. Naturally, we can stack multiple Graph Convolution layers alternating them with activation functions, just like we do in CNNs. Thus we get Graph Convolution Network (GCN).\n",
    "   ![adjacency_matrix_07](./img/adjacency_matrix_07.png)\n",
    "\n",
    "2. Let’s now outline the whole GCN pipeline we are going to use in our example. We have a graph with $C$ nodes, and we would like to apply the GCN. The goal of Graph Convolutional operation is to learn a function of input/output features. Given a **(directional)** graph $G=(Vertex, E)$, GCN takes as input:\n",
    "  + it takes a $C\\times D$ feature matrix ($D$ is the dimension of the input features), and\n",
    "  + a weighted adjacency matrix $P$ that represents the graph structure in a matrix form.\n",
    "\n",
    "  Then several Graph Convolutions are applied sequentially with ReLU as an activation function. The output of Graph Convolutional operation is a $C\\times F$ feature matrix, where $F$ is the number of output features per node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1066d182990e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mGraphConvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"\n\u001b[1;32m      3\u001b[0m         \u001b[0mSimple\u001b[0m \u001b[0mGCN\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilar\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1609.02907\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    \"\"\"\n",
    "        Simple GCN layer, similar to \n",
    "        https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features_dim, out_features_dim, bias=False):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features_dim = in_features_dim\n",
    "        self.out_features_dim = out_features_dim\n",
    "        self.weight = Parameter(\n",
    "                  torch.Tensor(in_features_dim, out_features_dim), #☆ Weight determines the dim of out_features. \n",
    "                  requires_grad=True)\n",
    "        if bias:\n",
    "            self.bias = Parameter(\n",
    "                         torch.Tensor(1, 1, out_features_dim), \n",
    "                         requires_grad=True)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.matmul(input.float(),\n",
    "                               self.weight.float())\n",
    "        output = torch.matmul(adj, support) #Adjacency matrix\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features_dim) + ' -> ' \\\n",
    "               + str(self.out_features_dim) + ')'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Label vectorization (GloVe)\n",
    "\n",
    "We just discussed how GCNs work and how they take a feature matrix as input with a feature vector per node. **In our task though, we don’t have any features for labels, just their names. (BW: That's why we need to encode the texts.)** When working with text in neural networks, a vector representation of words is usually used. Each vector represents a specific word in the space of all words of the corpus (dictionary) on which this space was calculated. The space of words is necessary to find the relationships between the words: the closer the vectors are to each other in this space, the closer their meanings are. You may see that the words with close meanings (like sky, sun, clouds) are close in the feature space. There are various approaches to obtaining this space, in our example, we use the **GloVe model** built on Wikipedia with a feature vector of length 300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 ML-GCN\n",
    "We are going to implement the approach from the *Multi-Label Image Recognition with Graph Convolutional Networks* paper. It consists of applying all the steps described earlier:\n",
    "\n",
    "+ [x] Calculate a weighted adjacency matrix from the training set.\n",
    "+ [x] Calculate the matrix with per-label features: X=LxD\n",
    "+ [x] Use vectorized labels X and weighted adjacency matrix P as the input of the graph neural network, and preprocessed image as the input for the CNN network.\n",
    "+ [x] Train the model!\n",
    "\n",
    "We’d like to discuss several practical tricks left before moving to the implementation of this approach.\n",
    "\n",
    "When training on real data, usually the following problems arise: overfitting and over-smoothing. The ways to solve them when working with the Multi-Label Graph Convolutional Networks (ML-GCN) are described below.👇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8.1 Weighted adjacency matrix thresholding\n",
    "\n",
    "To avoid overfitting, we filter the pairs in the weighted adjacency matrix that have probabilities lower than a certain threshold τ (we use τ=0.1). Such edges we interpret as being poorly represented or error connections. That may happen, for example, due to the noise in training data. For example, in our case such connections are ‘birds’ and ‘nighttime’: they represent random coincidences rather than real relations.\n",
    "    \\begin{equation}\n",
    "        \\boldsymbol{A}_{i j}=\\left\\{\\begin{array}{ll}\n",
    "        0, & \\text { if } \\boldsymbol{P}_{i j}<\\tau \\\\\n",
    "        1, & \\text { if } \\boldsymbol{P}_{i j} \\geq \\tau\n",
    "    \\end{array}\\right.\n",
    "    \\end{equation}\n",
    "\n",
    "#### 1.8.2 Over-smoothing problem\n",
    "\n",
    "☆ After applying a Graph Convolution layer, the feature of the node will be the weighted sum of its own feature and the adjacent nodes’ features. The reweighted adjacency matrix is shown below:\n",
    "    \\begin{equation}\n",
    "        \\boldsymbol{A}_{i j}^{\\prime}=\\left\\{\\begin{array}{ll}\n",
    "        p / \\sum_{j=1 \\atop i \\neq j}^{C} \\boldsymbol{A}_{i j}, & \\text { if } i \\neq j \\\\\n",
    "        1-p, & \\text { if } i=j\n",
    "    \\end{array}\\right.\n",
    "    \\end{equation}\n",
    "\n",
    "It may result in an over-smoothing of the features in a particular node, especially after applying several layers. To prevent this, we introduce a parameter p that calibrates the weights assigned to the node itself and other correlated nodes. By doing this, when updating the node feature, we will have a fixed weight for the node itself, and the weights for its neighbor nodes will be determined by the neighborhood distribution. When p → 1, the feature of the node itself will not be considered. On the other hand, when p → 0, neighboring information tends to be ignored. In our experiments, we use p=0.25.\n",
    "\n",
    "### 1.9 GCN\n",
    "Finally, let’s construct the model with GCN. We took the first 4 layers from $ResNeXt50$ as a visual feature extractor and used multi-layer GCN as a label relationship extractor. Features from the image itself and the labels are then combined via a dot product operation. See the scheme below:\n",
    "    ![ML_GCN_arch](./img/ML_GCN_arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adjacency matrix from statistics.\n",
    "def gen_A(num_classes, t, p, adj_data):\n",
    "    adj = np.array(adj_data['adj']).astype(np.float32)\n",
    "    nums = np.array(adj_data['nums']).astype(np.float32)\n",
    "    nums = nums[:, np.newaxis]\n",
    "    adj = adj / nums\n",
    "    adj[adj < t] = 0    #☆ Weighted adjacency matrix thresholding\n",
    "    adj[adj >= t] = 1\n",
    "    adj = adj * p / (adj.sum(0, keepdims=True) + 1e-6)    #☆ Over-smoothing problem\n",
    "    adj = adj + np.identity(num_classes, np.int)\n",
    "    return adj\n",
    "\n",
    "# Apply adjacency matrix re-normalization trick.\n",
    "def gen_adj(A):\n",
    "    D = torch.pow(A.sum(1).float(), -0.5)  #☆ sum(axis=1): each row stands for the start (directional) node\n",
    "    D = torch.diag(D).type_as(A)\n",
    "    adj = torch.matmul(torch.matmul(A, D).t(), D)\n",
    "    return adj\n",
    "\n",
    "\n",
    "class GCNResnext50(nn.Module):\n",
    "    def __init__(self, n_classes, adj_path, in_channel=300, #☆ X0 feature dim 300: (texts) label vectorization\n",
    "                 t=0.1, p=0.25):\n",
    "        super().__init__()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "        self.features = models.resnext50_32x4d(pretrained=True)\n",
    "        self.features.fc = nn.Identity()\n",
    "        self.num_classes = n_classes\n",
    "\n",
    "        self.gc1 = GraphConvolution(in_channel, 1024)\n",
    "        self.gc2 = GraphConvolution(1024, 2048)\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        # Load statistics data for adjacency matrix\n",
    "        with open(adj_path) as fp:\n",
    "            adj_data = json.load(fp)\n",
    "        # Compute adjacency matrix\n",
    "        adj = gen_A(n_classes, t, p, adj_data)\n",
    "        self.A = Parameter(torch.from_numpy(adj).float(), \n",
    "                           requires_grad=False)\n",
    "\n",
    "    def forward(self, imgs, inp):\n",
    "        # Get visual features from image\n",
    "        feature = self.features(imgs)\n",
    "        feature = feature.view(feature.size(0), -1)\n",
    "        \n",
    "        # Get graph features from graph\n",
    "        inp = inp[0].squeeze()\n",
    "        adj = gen_adj(self.A).detach() #☆ copy without gradients\n",
    "        x = self.gc1(inp, adj)\n",
    "        x = self.relu(x)\n",
    "        x = self.gc2(x, adj)\n",
    "        \n",
    "        # We multiply the features from GCN and CNN in order to \n",
    "        # take into account the contribution to the prediction of \n",
    "        # classes from both the image and the graph.\n",
    "        x = x.transpose(0, 1)\n",
    "        x = torch.matmul(feature, x)\n",
    "        return self.sigm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.10 Accuracy comparison with the earlier post\n",
    "\n",
    "Comparing ML-GCN with the naive approach from <span style=\"color:#B40431;background-color:#FBEFF2\"> [the earlier post](https://www.learnopencv.com/multi-label-image-classification-with-pytorch-image-tagging/) </span>, we find that ML-GCN approach is more accurate:\n",
    "    ![GCN_result_01](./img/GCN_result_01.png)\n",
    "\n",
    "### 1.11 Summary\n",
    "In this post, we’ve shown how to represent the graph structure in CNN, and how Graph Convolutional Networks works. We also applied them to a real-life task: multi-label classification of images. GCN has significantly increased the baseline accuracy there proving that GCNs are a powerful tool that can be used to further improve the quality and performance of a broad range of deep learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
